{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import datetime\n",
    "import copy\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "#disable warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alignPastCurrentPOI(checkins, dateList):\n",
    "    \n",
    "    #sort the checkins and then al\n",
    "\n",
    "    #sort the checkins \n",
    "    #group by userId, then checkin date and then order by time \n",
    "    uniqueUserIds = np.unique(checkins['userid'])\n",
    "    uniqueCheckinDates = sorted(np.unique(dateList))\n",
    "\n",
    "    #sort checkins by userid and date\n",
    "    sortedCheckins = pd.DataFrame([])\n",
    "\n",
    "    for userId in uniqueUserIds:\n",
    "        for checkinDate in uniqueCheckinDates:\n",
    "\n",
    "            #group by userId and checkin date \n",
    "            groupedByUserId = checkins[userId==checkins['userid']]\n",
    "            groupedByCheckinDate = groupedByUserId[groupedByUserId['Date'] == checkinDate]\n",
    "            if groupedByCheckinDate.shape[0] == 0:\n",
    "                continue\n",
    "\n",
    "            #sort by time \n",
    "            groupedByCheckinDate.sort_values(by ='Time',ascending=True, inplace=True)\n",
    "            groupedByCheckinDate.index = range(0, groupedByCheckinDate.shape[0])\n",
    "\n",
    "            #create list of sorted checkins \n",
    "            sortedCheckins = pd.concat([sortedCheckins, groupedByCheckinDate], axis=0, ignore_index=True)\n",
    "            \n",
    "    #align past and current checkins - features and labels entire df\n",
    "    pastCurrentCheckins = pd.DataFrame([])\n",
    "\n",
    "    for userId in uniqueUserIds:\n",
    "\n",
    "        #group by userId\n",
    "        groupedByUserId = sortedCheckins[userId==checkins['userid']]\n",
    "        tempDf = pd.DataFrame([]) #holds the current user and instance\n",
    "\n",
    "        for rowIndex in groupedByUserId.index:\n",
    "\n",
    "            try:\n",
    "                pastPOI = groupedByUserId.loc[rowIndex][['Community','Entertainment','Food','Nightlife','Outdoors','Shopping','Travel']]\n",
    "                currentPOI = groupedByUserId.loc[rowIndex+1]\n",
    "                poiInstance = list(currentPOI) + list(pastPOI)\n",
    "                tempDf = pd.concat([tempDf, pd.DataFrame(poiInstance).T], axis=0)\n",
    "            except KeyError:\n",
    "                break\n",
    "\n",
    "\n",
    "        #add the first row\n",
    "        firstRow = groupedByUserId.loc[groupedByUserId.index[0]]\n",
    "        poiInstance = list(firstRow) + [0,0,0,0,0,0,0] #0's represent no POI location\n",
    "        tempDf = pd.concat([pd.DataFrame(poiInstance).T,tempDf], axis=0)\n",
    "        pastCurrentCheckins = pd.concat([pastCurrentCheckins, tempDf], axis=0)   \n",
    "\n",
    "    #rename fields \n",
    "    pastCurrentCheckinDfColumnNames = ['Current ' + name for name in sortedCheckins.columns] + ['Past ' + name for name in ['Community','Entertainment','Food','Nightlife','Outdoors','Shopping','Travel']]\n",
    "    pastCurrentCheckins.columns = pastCurrentCheckinDfColumnNames\n",
    "    \n",
    "    return pastCurrentCheckins\n",
    "\n",
    "def preprocessing():\n",
    "    \n",
    "    #import data\n",
    "    checkinsDf = pd.read_csv(\"/home/usermobilitymining/Notebooks/volume/Hasnain/Processed Data/processedCheckins.csv\")\n",
    "    nzCheckins = pd.read_csv(\"/home/usermobilitymining/Notebooks/volume/Hasnain/Processed Data/nzCheckinsWithGridTokens.csv\")\n",
    "\n",
    "    #join checkins df and nz checkins to only extract NZ checkins \n",
    "    checkinsDf['id'] = checkinsDf.index #create id field\n",
    "    nzCheckins.drop(\"lat\", axis=1, inplace=True) #drop lat so no error\n",
    "    nzCheckins.drop(\"lng\", axis=1, inplace=True) #drop lng so no error\n",
    "    checkinsDf = nzCheckins.join(checkinsDf.set_index('id'), on='id')\n",
    "    checkinsDf.drop(\"Unnamed: 0\", axis=1, inplace=True)\n",
    "    \n",
    "    #convert date and time to datetime variables\n",
    "    #extract day of the week and hour of checkin\n",
    "    checkinDate = [datetime.datetime.strptime(date, \"%Y-%m-%d\").date() for date in checkinsDf['Date']]\n",
    "    checkinDay = [date.weekday() for date in checkinDate]\n",
    "    checkinTime = [datetime.datetime.strptime(time, '%H:%M:%S').time() for time in checkinsDf['Time']]\n",
    "    checkinHour = [time.hour for time in checkinTime]\n",
    "    \n",
    "    #one hot encode the time variable\n",
    "    ohe = OneHotEncoder(dtype=np.int8, n_values=24)\n",
    "    hourOfCheckinEncoded = ohe.fit_transform(np.array(checkinHour).reshape(-1,1))\n",
    "    timeColumns = ['Time ' + str(num) for num in np.arange(0,24)]\n",
    "    timeDf = pd.DataFrame(hourOfCheckinEncoded.toarray(), columns=timeColumns)\n",
    "\n",
    "    #one hot encode the day of the week variable\n",
    "    ohe = OneHotEncoder(dtype=np.int8, n_values=7)\n",
    "    dayOfTheWeekEncoded = ohe.fit_transform(np.array(checkinDay).reshape(-1,1))\n",
    "    dayColumns = ['DayOfWeek ' + str(num) for num in np.arange(0,7)]\n",
    "    dayDf = pd.DataFrame(dayOfTheWeekEncoded.toarray(), columns=dayColumns)\n",
    "\n",
    "    #one hot encode the main category\n",
    "    numberOfMainCategories = len(np.unique(checkinsDf['Main Category']))\n",
    "    labelEncoder = LabelEncoder()\n",
    "    mainCategoriesEncoded = labelEncoder.fit_transform(checkinsDf['Main Category'].values.reshape(-1,1))\n",
    "    ohe = OneHotEncoder(dtype=np.int8, n_values=numberOfMainCategories)\n",
    "    mainCategoriesEncoded = ohe.fit_transform(mainCategoriesEncoded.reshape(-1,1))\n",
    "    categoryDf = pd.DataFrame(mainCategoriesEncoded.toarray(), columns=labelEncoder.classes_)\n",
    "    \n",
    "    #concat fields\n",
    "    checkinsDf = pd.concat([checkinsDf, timeDf], axis=1,copy=False) \n",
    "    checkinsDf = pd.concat([checkinsDf, dayDf], axis=1,copy=False) \n",
    "    checkinsDf = pd.concat([checkinsDf, categoryDf], axis=1,copy=False) \n",
    "    \n",
    "    #past present align\n",
    "    dateList = np.unique(checkinsDf['Date'])\n",
    "    checkinsDf = alignPastCurrentPOI(checkinsDf, dateList)\n",
    "    \n",
    "    #drop fields \n",
    "    checkinsDf.drop(\"Current Date\", axis=1, inplace=True)\n",
    "    checkinsDf.drop(\"Current Time\", axis=1, inplace=True)\n",
    "    checkinsDf.drop(\"Current Main Category\", axis=1, inplace=True)\n",
    "    checkinsDf.drop(\"Current Locations\", axis=1, inplace=True)\n",
    "    \n",
    "    #label feature split\n",
    "    labelDf = checkinsDf[['Current Community','Current Entertainment','Current Food',\n",
    "                          'Current Nightlife','Current Outdoors','Current Shopping','Current Travel']]\n",
    "    featuresDf = checkinsDf.drop(['Current Community','Current Entertainment','Current Food','Current Nightlife',\n",
    "                                  'Current Outdoors','Current Shopping','Current Travel'], axis=1)\n",
    "\n",
    "    \n",
    "\n",
    "    return featuresDf, labelDf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresDf, labelDf = preprocessing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#integer encode the labels\n",
    "labels = list()\n",
    "for i in range(0, labelDf.shape[0]):\n",
    "    labels.append(np.argmax(labelDf.values[i]))\n",
    "    \n",
    "labelDf = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert dtype\n",
    "featuresDf = featuresDf.astype(float)\n",
    "labelDf = labelDf.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train test split\n",
    "featuresTrain, featuresTest, labelTrain, labelTest = train_test_split(featuresDf, labelDf, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
       "              min_child_weight=1, missing=None, n_estimators=1000, n_jobs=-1,\n",
       "              nthread=None, objective='multi:softprob', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "              silent=None, subsample=1, verbosity=1)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train model\n",
    "clf = XGBClassifier(n_estimators=1000, n_jobs=-1)\n",
    "clf.fit(featuresTrain, labelTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use model to predict\n",
    "labelPredicted = clf.predict(featuresTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  88.1406288685318\n"
     ]
    }
   ],
   "source": [
    "#accuracy\n",
    "a = accuracy_score(labelPredicted,labelTest)\n",
    "print(\"Accuracy: \", a*100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
