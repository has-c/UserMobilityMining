{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/has-c/UserMobilityMining/blob/master/Gowalla%20ANN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 80
    },
    "colab_type": "code",
    "id": "AniSM0JZu5fr",
    "outputId": "0b37c1aa-6145-461a-ed36-5d47d0275141"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/usermobilitymining/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/usermobilitymining/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/usermobilitymining/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/usermobilitymining/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/usermobilitymining/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/usermobilitymining/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/usermobilitymining/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/usermobilitymining/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/usermobilitymining/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/usermobilitymining/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/usermobilitymining/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/usermobilitymining/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, Softmax\n",
    "from sklearn.metrics import accuracy_score\n",
    "import datetime\n",
    "import copy\n",
    "\n",
    "#disable warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alignPastCurrentPOI(checkins, dateList):\n",
    "    \n",
    "    #sort the checkins and then al\n",
    "\n",
    "    #sort the checkins \n",
    "    #group by userId, then checkin date and then order by time \n",
    "    uniqueUserIds = np.unique(checkins['userid'])\n",
    "    uniqueCheckinDates = sorted(np.unique(dateList))\n",
    "\n",
    "    #sort checkins by userid and date\n",
    "    sortedCheckins = pd.DataFrame([])\n",
    "\n",
    "    for userId in uniqueUserIds:\n",
    "        for checkinDate in uniqueCheckinDates:\n",
    "\n",
    "            #group by userId and checkin date \n",
    "            groupedByUserId = checkins[userId==checkins['userid']]\n",
    "            groupedByCheckinDate = groupedByUserId[groupedByUserId['Date'] == checkinDate]\n",
    "            if groupedByCheckinDate.shape[0] == 0:\n",
    "                continue\n",
    "\n",
    "            #sort by time \n",
    "            groupedByCheckinDate.sort_values(by ='Time',ascending=True, inplace=True)\n",
    "            groupedByCheckinDate.index = range(0, groupedByCheckinDate.shape[0])\n",
    "\n",
    "            #create list of sorted checkins \n",
    "            sortedCheckins = pd.concat([sortedCheckins, groupedByCheckinDate], axis=0, ignore_index=True)\n",
    "            \n",
    "    #align past and current checkins - features and labels entire df\n",
    "    pastCurrentCheckins = pd.DataFrame([])\n",
    "\n",
    "    for userId in uniqueUserIds:\n",
    "\n",
    "        #group by userId\n",
    "        groupedByUserId = sortedCheckins[userId==checkins['userid']]\n",
    "        tempDf = pd.DataFrame([]) #holds the current user and instance\n",
    "\n",
    "        for rowIndex in groupedByUserId.index:\n",
    "\n",
    "            try:\n",
    "                pastPOI = groupedByUserId.loc[rowIndex][['Community','Entertainment','Food','Nightlife','Outdoors','Shopping','Travel']]\n",
    "                currentPOI = groupedByUserId.loc[rowIndex+1]\n",
    "                poiInstance = list(currentPOI) + list(pastPOI)\n",
    "                tempDf = pd.concat([tempDf, pd.DataFrame(poiInstance).T], axis=0)\n",
    "            except KeyError:\n",
    "                break\n",
    "\n",
    "\n",
    "        #add the first row\n",
    "        firstRow = groupedByUserId.loc[groupedByUserId.index[0]]\n",
    "        poiInstance = list(firstRow) + [0,0,0,0,0,0,0] #0's represent no POI location\n",
    "        tempDf = pd.concat([pd.DataFrame(poiInstance).T,tempDf], axis=0)\n",
    "        pastCurrentCheckins = pd.concat([pastCurrentCheckins, tempDf], axis=0)   \n",
    "\n",
    "    #rename fields \n",
    "    pastCurrentCheckinDfColumnNames = ['Current ' + name for name in sortedCheckins.columns] + ['Past ' + name for name in ['Community','Entertainment','Food','Nightlife','Outdoors','Shopping','Travel']]\n",
    "    pastCurrentCheckins.columns = pastCurrentCheckinDfColumnNames\n",
    "    \n",
    "    return pastCurrentCheckins\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing \n",
    "<ul>\n",
    "    <li> One hot encoding </li>\n",
    "    <li> Standard scaling </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import data\n",
    "checkinsDf = pd.read_csv(\"/home/usermobilitymining/Notebooks/volume/Hasnain/Processed Data/processedCheckins.csv\")\n",
    "nzCheckins = pd.read_csv(\"/home/usermobilitymining/Notebooks/volume/Hasnain/Processed Data/nzCheckinsWithGridTokens.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#join checkins df and nz checkins to only extract NZ checkins \n",
    "checkinsDf['id'] = checkinsDf.index #create id field\n",
    "nzCheckins.drop(\"lat\", axis=1, inplace=True) #drop lat so no error\n",
    "nzCheckins.drop(\"lng\", axis=1, inplace=True) #drop lng so no error\n",
    "checkinsDf = nzCheckins.join(checkinsDf.set_index('id'), on='id')\n",
    "checkinsDf.drop(\"Unnamed: 0\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert date and time to datetime variables\n",
    "#extract day of the week and hour of checkin\n",
    "checkinDate = [datetime.datetime.strptime(date, \"%Y-%m-%d\").date() for date in checkinsDf['Date']]\n",
    "checkinDay = [date.weekday() for date in checkinDate]\n",
    "checkinTime = [datetime.datetime.strptime(time, '%H:%M:%S').time() for time in checkinsDf['Time']]\n",
    "checkinHour = [time.hour for time in checkinTime]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one hot encode the time variable\n",
    "ohe = OneHotEncoder(dtype=np.int8, n_values=24)\n",
    "hourOfCheckinEncoded = ohe.fit_transform(np.array(checkinHour).reshape(-1,1))\n",
    "timeColumns = ['Time ' + str(num) for num in np.arange(0,24)]\n",
    "timeDf = pd.DataFrame(hourOfCheckinEncoded.toarray(), columns=timeColumns)\n",
    "\n",
    "#one hot encode the day of the week variable\n",
    "ohe = OneHotEncoder(dtype=np.int8, n_values=7)\n",
    "dayOfTheWeekEncoded = ohe.fit_transform(np.array(checkinDay).reshape(-1,1))\n",
    "dayColumns = ['DayOfWeek ' + str(num) for num in np.arange(0,7)]\n",
    "dayDf = pd.DataFrame(dayOfTheWeekEncoded.toarray(), columns=dayColumns)\n",
    "\n",
    "#one hot encode the main category\n",
    "numberOfMainCategories = len(np.unique(checkinsDf['Main Category']))\n",
    "labelEncoder = LabelEncoder()\n",
    "mainCategoriesEncoded = labelEncoder.fit_transform(checkinsDf['Main Category'].values.reshape(-1,1))\n",
    "ohe = OneHotEncoder(dtype=np.int8, n_values=numberOfMainCategories)\n",
    "mainCategoriesEncoded = ohe.fit_transform(mainCategoriesEncoded.reshape(-1,1))\n",
    "categoryDf = pd.DataFrame(mainCategoriesEncoded.toarray(), columns=labelEncoder.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#concat fields\n",
    "checkinsDf = pd.concat([checkinsDf, timeDf], axis=1,copy=False) \n",
    "checkinsDf = pd.concat([checkinsDf, dayDf], axis=1,copy=False) \n",
    "checkinsDf = pd.concat([checkinsDf, categoryDf], axis=1,copy=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dateList = np.unique(checkinsDf['Date'])\n",
    "checkinsDf = alignPastCurrentPOI(checkinsDf, dateList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop fields \n",
    "checkinsDf.drop(\"Current Date\", axis=1, inplace=True)\n",
    "checkinsDf.drop(\"Current Time\", axis=1, inplace=True)\n",
    "checkinsDf.drop(\"Current Main Category\", axis=1, inplace=True)\n",
    "checkinsDf.drop(\"Current Locations\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train test split - normal \n",
    "labelDf = checkinsDf[['Current Community','Current Entertainment','Current Food',\n",
    "                      'Current Nightlife','Current Outdoors','Current Shopping','Current Travel']]\n",
    "featuresDf = checkinsDf.drop(['Current Community','Current Entertainment','Current Food','Current Nightlife',\n",
    "                              'Current Outdoors','Current Shopping','Current Travel'], axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#standardize features\n",
    "scaler = StandardScaler() \n",
    "featuresDf = scaler.fit_transform(featuresDf)\n",
    "\n",
    "#add header \n",
    "featuresDf = pd.DataFrame(featuresDf, columns=header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train test split\n",
    "featuresTrain, featuresTest, labelTrain, labelTest = train_test_split(featuresDf, labelDf, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m9K3b-Q9vadV"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(100, input_dim=52, activation='relu'))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(20, activation='relu'))\n",
    "model.add(Dense(7, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nDAO7Colvaj2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/100\n",
      "16156/16156 [==============================] - 1s 61us/step - loss: -1046.2791 - accuracy: 0.1860\n",
      "Epoch 2/100\n",
      "16156/16156 [==============================] - 1s 46us/step - loss: -290419.7455 - accuracy: 0.1775\n",
      "Epoch 3/100\n",
      "16156/16156 [==============================] - 1s 44us/step - loss: -11586578.6252 - accuracy: 0.1787\n",
      "Epoch 4/100\n",
      "16156/16156 [==============================] - 1s 43us/step - loss: -109409372.3575 - accuracy: 0.1784\n",
      "Epoch 5/100\n",
      "16156/16156 [==============================] - 1s 43us/step - loss: -536909276.2605 - accuracy: 0.1825\n",
      "Epoch 6/100\n",
      "16156/16156 [==============================] - 1s 43us/step - loss: -1749231722.5452 - accuracy: 0.1817\n",
      "Epoch 7/100\n",
      "16156/16156 [==============================] - 1s 45us/step - loss: -4409013824.4595 - accuracy: 0.1853\n",
      "Epoch 8/100\n",
      "16156/16156 [==============================] - 1s 45us/step - loss: -9128177216.2694 - accuracy: 0.1847\n",
      "Epoch 9/100\n",
      "16156/16156 [==============================] - 1s 45us/step - loss: -16656644164.9596 - accuracy: 0.1839\n",
      "Epoch 10/100\n",
      "16156/16156 [==============================] - 1s 45us/step - loss: -27877760766.4154 - accuracy: 0.1843\n",
      "Epoch 11/100\n",
      "16156/16156 [==============================] - 1s 46us/step - loss: -44072686401.6004 - accuracy: 0.1874\n",
      "Epoch 12/100\n",
      "16156/16156 [==============================] - 1s 46us/step - loss: -66400277658.3986 - accuracy: 0.1860\n",
      "Epoch 13/100\n",
      "16156/16156 [==============================] - 1s 44us/step - loss: -95654298504.5883 - accuracy: 0.1852\n",
      "Epoch 14/100\n",
      "16156/16156 [==============================] - 1s 44us/step - loss: -133814092143.1087 - accuracy: 0.1852\n",
      "Epoch 15/100\n",
      "16156/16156 [==============================] - 1s 46us/step - loss: -182229218082.1629 - accuracy: 0.1835\n",
      "Epoch 16/100\n",
      "16156/16156 [==============================] - 1s 47us/step - loss: -242407387090.3649 - accuracy: 0.1869\n",
      "Epoch 17/100\n",
      "16156/16156 [==============================] - 1s 46us/step - loss: -316991214708.8765 - accuracy: 0.1854\n",
      "Epoch 18/100\n",
      "16156/16156 [==============================] - 1s 46us/step - loss: -407435938680.8695 - accuracy: 0.1849\n",
      "Epoch 19/100\n",
      "16156/16156 [==============================] - 1s 44us/step - loss: -515740542925.8014 - accuracy: 0.1864\n",
      "Epoch 20/100\n",
      "16156/16156 [==============================] - 1s 44us/step - loss: -643896047812.2307 - accuracy: 0.1838\n",
      "Epoch 21/100\n",
      "16156/16156 [==============================] - 1s 44us/step - loss: -795361463310.9581 - accuracy: 0.1848\n",
      "Epoch 22/100\n",
      "16156/16156 [==============================] - 1s 46us/step - loss: -973660684166.3065 - accuracy: 0.1869\n",
      "Epoch 23/100\n",
      "16156/16156 [==============================] - 1s 46us/step - loss: -1179747348292.3892 - accuracy: 0.1861\n",
      "Epoch 24/100\n",
      "16156/16156 [==============================] - 1s 45us/step - loss: -1417218356018.3887 - accuracy: 0.1856\n",
      "Epoch 25/100\n",
      "16156/16156 [==============================] - 1s 44us/step - loss: -1688574993026.9473 - accuracy: 0.1832\n",
      "Epoch 26/100\n",
      "16156/16156 [==============================] - 1s 44us/step - loss: -2001165157958.3540 - accuracy: 0.1928\n",
      "Epoch 27/100\n",
      "16156/16156 [==============================] - 1s 44us/step - loss: -2354718888590.1025 - accuracy: 0.1853\n",
      "Epoch 28/100\n",
      "16156/16156 [==============================] - 1s 44us/step - loss: -2754469453035.0210 - accuracy: 0.1876\n",
      "Epoch 29/100\n",
      "16156/16156 [==============================] - 1s 44us/step - loss: -3202394330419.5293 - accuracy: 0.1858\n",
      "Epoch 30/100\n",
      "16156/16156 [==============================] - 1s 45us/step - loss: -3705783794077.2505 - accuracy: 0.1892\n",
      "Epoch 31/100\n",
      "16156/16156 [==============================] - 1s 42us/step - loss: -4268745426031.8057 - accuracy: 0.1902\n",
      "Epoch 32/100\n",
      "16156/16156 [==============================] - ETA: 0s - loss: -4878953198612.7285 - accuracy: 0.184"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-19-a65b59d612ff>\", line 2, in <module>\n",
      "    history = model.fit(featuresTrain, labelTrain, epochs=100)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\", line 1239, in fit\n",
      "    validation_freq=validation_freq)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\", line 216, in fit_loop\n",
      "    callbacks.on_epoch_end(epoch, epoch_logs)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/keras/callbacks/callbacks.py\", line 152, in on_epoch_end\n",
      "    callback.on_epoch_end(epoch, logs)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/keras/callbacks/callbacks.py\", line 611, in on_epoch_end\n",
      "    self.progbar.update(self.seen, self.log_values)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/keras/utils/generic_utils.py\", line 437, in update\n",
      "    self._values[k][0] / max(1, self._values[k][1]))\n",
      "  File \"<__array_function__ internals>\", line 6, in mean\n",
      "  File \"/home/usermobilitymining/.local/lib/python3.6/site-packages/numpy/core/fromnumeric.py\", line 3332, in mean\n",
      "    return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n",
      "  File \"/home/usermobilitymining/.local/lib/python3.6/site-packages/numpy/core/_methods.py\", line 145, in _mean\n",
      "    if issubclass(arr.dtype.type, (nt.integer, nt.bool_)):\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3/dist-packages/IPython/core/interactiveshell.py\", line 1823, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3/dist-packages/IPython/core/ultratb.py\", line 1132, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/usr/lib/python3/dist-packages/IPython/core/ultratb.py\", line 313, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/usr/lib/python3/dist-packages/IPython/core/ultratb.py\", line 358, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/usr/lib/python3.6/inspect.py\", line 1488, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/usr/lib/python3.6/inspect.py\", line 1446, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/usr/lib/python3.6/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/usr/lib/python3.6/inspect.py\", line 742, in getmodule\n",
      "    os.path.realpath(f)] = module.__name__\n",
      "  File \"/usr/lib/python3.6/posixpath.py\", line 388, in realpath\n",
      "    path, ok = _joinrealpath(filename[:0], filename, {})\n",
      "  File \"/usr/lib/python3.6/posixpath.py\", line 422, in _joinrealpath\n",
      "    if not islink(newpath):\n",
      "  File \"/usr/lib/python3.6/posixpath.py\", line 171, in islink\n",
      "    st = os.lstat(path)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "#fit model \n",
    "history = model.fit(featuresTrain, labelTrain, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RqICs5YLvaRS"
   },
   "outputs": [],
   "source": [
    "#predict\n",
    "labelPredicted = model.predict(featuresTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9.8425148e+01, 1.3858372e+00, 1.8206075e-01, 1.8255763e-03,\n",
       "       5.0743353e-03, 4.6015764e-05, 6.0991567e-09], dtype=float32)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#evaluate and find accuracy\n",
    "\n",
    "#Converting predictions to label\n",
    "pred = list()\n",
    "for i in range(len(labelPredicted)):\n",
    "    pred.append(np.argmax(labelPredicted[i]))\n",
    "#Converting one hot encoded test label to label\n",
    "test = list()\n",
    "for i in range(len(labelTest)):\n",
    "    test.append(np.argmax(labelTest[i]))\n",
    "\n",
    "#accuracy\n",
    "a = accuracy_score(pred,test)\n",
    "print(\"Accuracy: \", a*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Gowalla ANN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
